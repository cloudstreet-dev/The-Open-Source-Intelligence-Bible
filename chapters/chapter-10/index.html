<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A Comprehensive Technical Guide to Modern OSINT Practice"><meta name=author content=CloudStreet><link href=https://cloudstreet-dev.github.io/The-Open-Source-Intelligence-Bible/chapters/chapter-10/ rel=canonical><link href=../chapter-09/ rel=prev><link href=../chapter-11/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.3"><title>Ch 10: AI Fundamentals - The Open Source Intelligence Bible</title><link rel=stylesheet href=../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#chapter-10-ai-fundamentals-for-investigators class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="The Open Source Intelligence Bible" class="md-header__button md-logo" aria-label="The Open Source Intelligence Bible" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> The Open Source Intelligence Bible </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Ch 10: AI Fundamentals </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/cloudstreet-dev/The-Open-Source-Intelligence-Bible title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> cloudstreet-dev/The-Open-Source-Intelligence-Bible </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../chapter-01/ class=md-tabs__link> Part I — Foundations </a> </li> <li class=md-tabs__item> <a href=../chapter-05/ class=md-tabs__link> Part II — Core Collection </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=./ class=md-tabs__link> Part III — AI and Data Processing </a> </li> <li class=md-tabs__item> <a href=../chapter-14/ class=md-tabs__link> Part IV — Automation and Tooling </a> </li> <li class=md-tabs__item> <a href=../chapter-18/ class=md-tabs__link> Part V — Applied Domains </a> </li> <li class=md-tabs__item> <a href=../chapter-23/ class=md-tabs__link> Part VI — Enterprise and Advanced </a> </li> <li class=md-tabs__item> <a href=../chapter-28/ class=md-tabs__link> Part VII — Professional Practice </a> </li> <li class=md-tabs__item> <a href=../../appendices/appendix-a-tool-reference/ class=md-tabs__link> Appendices </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="The Open Source Intelligence Bible" class="md-nav__button md-logo" aria-label="The Open Source Intelligence Bible" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> The Open Source Intelligence Bible </label> <div class=md-nav__source> <a href=https://github.com/cloudstreet-dev/The-Open-Source-Intelligence-Bible title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> cloudstreet-dev/The-Open-Source-Intelligence-Bible </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Part I — Foundations </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Part I — Foundations </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../chapter-01/ class=md-nav__link> <span class=md-ellipsis> Ch 1: What OSINT Is </span> </a> </li> <li class=md-nav__item> <a href=../chapter-02/ class=md-nav__link> <span class=md-ellipsis> Ch 2: The Data Landscape </span> </a> </li> <li class=md-nav__item> <a href=../chapter-03/ class=md-nav__link> <span class=md-ellipsis> Ch 3: Legal and Ethical Frameworks </span> </a> </li> <li class=md-nav__item> <a href=../chapter-04/ class=md-nav__link> <span class=md-ellipsis> Ch 4: Core Investigative Workflow </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Part II — Core Collection </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Part II — Core Collection </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../chapter-05/ class=md-nav__link> <span class=md-ellipsis> Ch 5: Social Media Intelligence </span> </a> </li> <li class=md-nav__item> <a href=../chapter-06/ class=md-nav__link> <span class=md-ellipsis> Ch 6: Domain and Network Recon </span> </a> </li> <li class=md-nav__item> <a href=../chapter-07/ class=md-nav__link> <span class=md-ellipsis> Ch 7: Public Records </span> </a> </li> <li class=md-nav__item> <a href=../chapter-08/ class=md-nav__link> <span class=md-ellipsis> Ch 8: Geospatial Intelligence </span> </a> </li> <li class=md-nav__item> <a href=../chapter-09/ class=md-nav__link> <span class=md-ellipsis> Ch 9: Advanced Search and Historical Data </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex> <span class=md-ellipsis> Part III — AI and Data Processing </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Part III — AI and Data Processing </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Ch 10: AI Fundamentals </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Ch 10: AI Fundamentals </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#learning-objectives class=md-nav__link> <span class=md-ellipsis> Learning Objectives </span> </a> </li> <li class=md-nav__item> <a href=#101-why-investigators-must-understand-ai class=md-nav__link> <span class=md-ellipsis> 10.1 Why Investigators Must Understand AI </span> </a> </li> <li class=md-nav__item> <a href=#102-machine-learning-fundamentals class=md-nav__link> <span class=md-ellipsis> 10.2 Machine Learning Fundamentals </span> </a> <nav class=md-nav aria-label="10.2 Machine Learning Fundamentals"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-machine-learning-is class=md-nav__link> <span class=md-ellipsis> What Machine Learning Is </span> </a> </li> <li class=md-nav__item> <a href=#neural-networks-and-deep-learning class=md-nav__link> <span class=md-ellipsis> Neural Networks and Deep Learning </span> </a> </li> <li class=md-nav__item> <a href=#transformers-and-the-attention-mechanism class=md-nav__link> <span class=md-ellipsis> Transformers and the Attention Mechanism </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#103-large-language-models-what-they-are-and-arent class=md-nav__link> <span class=md-ellipsis> 10.3 Large Language Models: What They Are and Aren't </span> </a> <nav class=md-nav aria-label="10.3 Large Language Models: What They Are and Aren't"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-llms-actually-do class=md-nav__link> <span class=md-ellipsis> What LLMs Actually Do </span> </a> </li> <li class=md-nav__item> <a href=#what-llms-are-not class=md-nav__link> <span class=md-ellipsis> What LLMs Are Not </span> </a> </li> <li class=md-nav__item> <a href=#the-hallucination-problem-for-investigators class=md-nav__link> <span class=md-ellipsis> The Hallucination Problem for Investigators </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#104-the-modern-ai-ecosystem-for-osint class=md-nav__link> <span class=md-ellipsis> 10.4 The Modern AI Ecosystem for OSINT </span> </a> <nav class=md-nav aria-label="10.4 The Modern AI Ecosystem for OSINT"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#foundation-model-providers class=md-nav__link> <span class=md-ellipsis> Foundation Model Providers </span> </a> </li> <li class=md-nav__item> <a href=#specialized-ai-models-relevant-to-osint class=md-nav__link> <span class=md-ellipsis> Specialized AI Models Relevant to OSINT </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#105-using-llms-in-investigative-practice class=md-nav__link> <span class=md-ellipsis> 10.5 Using LLMs in Investigative Practice </span> </a> <nav class=md-nav aria-label="10.5 Using LLMs in Investigative Practice"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#appropriate-llm-use-cases class=md-nav__link> <span class=md-ellipsis> Appropriate LLM Use Cases </span> </a> </li> <li class=md-nav__item> <a href=#inappropriate-llm-use-cases class=md-nav__link> <span class=md-ellipsis> Inappropriate LLM Use Cases </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#106-multimodal-ai-for-osint class=md-nav__link> <span class=md-ellipsis> 10.6 Multimodal AI for OSINT </span> </a> </li> <li class=md-nav__item> <a href=#107-ai-bias-and-its-investigative-implications class=md-nav__link> <span class=md-ellipsis> 10.7 AI Bias and Its Investigative Implications </span> </a> </li> <li class=md-nav__item> <a href=#108-responsible-ai-use-in-investigations class=md-nav__link> <span class=md-ellipsis> 10.8 Responsible AI Use in Investigations </span> </a> <nav class=md-nav aria-label="10.8 Responsible AI Use in Investigations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-human-oversight-requirement class=md-nav__link> <span class=md-ellipsis> The Human Oversight Requirement </span> </a> </li> <li class=md-nav__item> <a href=#prompt-design-for-investigative-use class=md-nav__link> <span class=md-ellipsis> Prompt Design for Investigative Use </span> </a> </li> <li class=md-nav__item> <a href=#data-privacy-in-ai-tool-use class=md-nav__link> <span class=md-ellipsis> Data Privacy in AI Tool Use </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#common-mistakes-and-pitfalls class=md-nav__link> <span class=md-ellipsis> Common Mistakes and Pitfalls </span> </a> </li> <li class=md-nav__item> <a href=#further-reading class=md-nav__link> <span class=md-ellipsis> Further Reading </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../chapter-11/ class=md-nav__link> <span class=md-ellipsis> Ch 11: Processing Unstructured Data at Scale </span> </a> </li> <li class=md-nav__item> <a href=../chapter-12/ class=md-nav__link> <span class=md-ellipsis> Ch 12: LLMs and Prompt Engineering </span> </a> </li> <li class=md-nav__item> <a href=../chapter-13/ class=md-nav__link> <span class=md-ellipsis> Ch 13: Network Analysis and Graph Intelligence </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Part IV — Automation and Tooling </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Part IV — Automation and Tooling </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../chapter-14/ class=md-nav__link> <span class=md-ellipsis> Ch 14: Automation and Investigative Pipelines </span> </a> </li> <li class=md-nav__item> <a href=../chapter-15/ class=md-nav__link> <span class=md-ellipsis> Ch 15: The OSINT Tool Ecosystem </span> </a> </li> <li class=md-nav__item> <a href=../chapter-16/ class=md-nav__link> <span class=md-ellipsis> Ch 16: AI-Enhanced Investigative Platforms </span> </a> </li> <li class=md-nav__item> <a href=../chapter-17/ class=md-nav__link> <span class=md-ellipsis> Ch 17: Visualization and Reporting </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Part V — Applied Domains </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Part V — Applied Domains </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../chapter-18/ class=md-nav__link> <span class=md-ellipsis> Ch 18: Private Investigator Workflows </span> </a> </li> <li class=md-nav__item> <a href=../chapter-19/ class=md-nav__link> <span class=md-ellipsis> Ch 19: Bounty Hunting and Vulnerability Research </span> </a> </li> <li class=md-nav__item> <a href=../chapter-20/ class=md-nav__link> <span class=md-ellipsis> Ch 20: Threat Intelligence and Cybersecurity </span> </a> </li> <li class=md-nav__item> <a href=../chapter-21/ class=md-nav__link> <span class=md-ellipsis> Ch 21: Financial Crime and AML </span> </a> </li> <li class=md-nav__item> <a href=../chapter-22/ class=md-nav__link> <span class=md-ellipsis> Ch 22: Corporate Security and Due Diligence </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_7> <label class=md-nav__link for=__nav_7 id=__nav_7_label tabindex=0> <span class=md-ellipsis> Part VI — Enterprise and Advanced </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Part VI — Enterprise and Advanced </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../chapter-23/ class=md-nav__link> <span class=md-ellipsis> Ch 23: Enterprise-Scale Analysis </span> </a> </li> <li class=md-nav__item> <a href=../chapter-24/ class=md-nav__link> <span class=md-ellipsis> Ch 24: Adversarial OSINT and Counter-Intelligence </span> </a> </li> <li class=md-nav__item> <a href=../chapter-25/ class=md-nav__link> <span class=md-ellipsis> Ch 25: Emerging Technologies and Future AI </span> </a> </li> <li class=md-nav__item> <a href=../chapter-26/ class=md-nav__link> <span class=md-ellipsis> Ch 26: Operational Security and Risk Management </span> </a> </li> <li class=md-nav__item> <a href=../chapter-27/ class=md-nav__link> <span class=md-ellipsis> Ch 27: Designing Your OSINT Stack </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_8> <label class=md-nav__link for=__nav_8 id=__nav_8_label tabindex=0> <span class=md-ellipsis> Part VII — Professional Practice </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_8_label aria-expanded=false> <label class=md-nav__title for=__nav_8> <span class="md-nav__icon md-icon"></span> Part VII — Professional Practice </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../chapter-28/ class=md-nav__link> <span class=md-ellipsis> Ch 28: Real-World Case Studies </span> </a> </li> <li class=md-nav__item> <a href=../chapter-29/ class=md-nav__link> <span class=md-ellipsis> Ch 29: Pitfalls, Bias, and Failure Modes </span> </a> </li> <li class=md-nav__item> <a href=../chapter-30/ class=md-nav__link> <span class=md-ellipsis> Ch 30: The Future of OSINT Practice </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_9> <label class=md-nav__link for=__nav_9 id=__nav_9_label tabindex=0> <span class=md-ellipsis> Appendices </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_9_label aria-expanded=false> <label class=md-nav__title for=__nav_9> <span class="md-nav__icon md-icon"></span> Appendices </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../appendices/appendix-a-tool-reference/ class=md-nav__link> <span class=md-ellipsis> Appendix A: Tool Reference </span> </a> </li> <li class=md-nav__item> <a href=../../appendices/appendix-b-python-examples/ class=md-nav__link> <span class=md-ellipsis> Appendix B: Python Code Examples </span> </a> </li> <li class=md-nav__item> <a href=../../appendices/appendix-c-legal-resources/ class=md-nav__link> <span class=md-ellipsis> Appendix C: Legal Resources </span> </a> </li> <li class=md-nav__item> <a href=../../appendices/appendix-d-glossary/ class=md-nav__link> <span class=md-ellipsis> Appendix D: Glossary </span> </a> </li> <li class=md-nav__item> <a href=../../appendices/appendix-e-further-reading/ class=md-nav__link> <span class=md-ellipsis> Appendix E: Further Reading </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#learning-objectives class=md-nav__link> <span class=md-ellipsis> Learning Objectives </span> </a> </li> <li class=md-nav__item> <a href=#101-why-investigators-must-understand-ai class=md-nav__link> <span class=md-ellipsis> 10.1 Why Investigators Must Understand AI </span> </a> </li> <li class=md-nav__item> <a href=#102-machine-learning-fundamentals class=md-nav__link> <span class=md-ellipsis> 10.2 Machine Learning Fundamentals </span> </a> <nav class=md-nav aria-label="10.2 Machine Learning Fundamentals"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-machine-learning-is class=md-nav__link> <span class=md-ellipsis> What Machine Learning Is </span> </a> </li> <li class=md-nav__item> <a href=#neural-networks-and-deep-learning class=md-nav__link> <span class=md-ellipsis> Neural Networks and Deep Learning </span> </a> </li> <li class=md-nav__item> <a href=#transformers-and-the-attention-mechanism class=md-nav__link> <span class=md-ellipsis> Transformers and the Attention Mechanism </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#103-large-language-models-what-they-are-and-arent class=md-nav__link> <span class=md-ellipsis> 10.3 Large Language Models: What They Are and Aren't </span> </a> <nav class=md-nav aria-label="10.3 Large Language Models: What They Are and Aren't"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-llms-actually-do class=md-nav__link> <span class=md-ellipsis> What LLMs Actually Do </span> </a> </li> <li class=md-nav__item> <a href=#what-llms-are-not class=md-nav__link> <span class=md-ellipsis> What LLMs Are Not </span> </a> </li> <li class=md-nav__item> <a href=#the-hallucination-problem-for-investigators class=md-nav__link> <span class=md-ellipsis> The Hallucination Problem for Investigators </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#104-the-modern-ai-ecosystem-for-osint class=md-nav__link> <span class=md-ellipsis> 10.4 The Modern AI Ecosystem for OSINT </span> </a> <nav class=md-nav aria-label="10.4 The Modern AI Ecosystem for OSINT"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#foundation-model-providers class=md-nav__link> <span class=md-ellipsis> Foundation Model Providers </span> </a> </li> <li class=md-nav__item> <a href=#specialized-ai-models-relevant-to-osint class=md-nav__link> <span class=md-ellipsis> Specialized AI Models Relevant to OSINT </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#105-using-llms-in-investigative-practice class=md-nav__link> <span class=md-ellipsis> 10.5 Using LLMs in Investigative Practice </span> </a> <nav class=md-nav aria-label="10.5 Using LLMs in Investigative Practice"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#appropriate-llm-use-cases class=md-nav__link> <span class=md-ellipsis> Appropriate LLM Use Cases </span> </a> </li> <li class=md-nav__item> <a href=#inappropriate-llm-use-cases class=md-nav__link> <span class=md-ellipsis> Inappropriate LLM Use Cases </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#106-multimodal-ai-for-osint class=md-nav__link> <span class=md-ellipsis> 10.6 Multimodal AI for OSINT </span> </a> </li> <li class=md-nav__item> <a href=#107-ai-bias-and-its-investigative-implications class=md-nav__link> <span class=md-ellipsis> 10.7 AI Bias and Its Investigative Implications </span> </a> </li> <li class=md-nav__item> <a href=#108-responsible-ai-use-in-investigations class=md-nav__link> <span class=md-ellipsis> 10.8 Responsible AI Use in Investigations </span> </a> <nav class=md-nav aria-label="10.8 Responsible AI Use in Investigations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-human-oversight-requirement class=md-nav__link> <span class=md-ellipsis> The Human Oversight Requirement </span> </a> </li> <li class=md-nav__item> <a href=#prompt-design-for-investigative-use class=md-nav__link> <span class=md-ellipsis> Prompt Design for Investigative Use </span> </a> </li> <li class=md-nav__item> <a href=#data-privacy-in-ai-tool-use class=md-nav__link> <span class=md-ellipsis> Data Privacy in AI Tool Use </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#common-mistakes-and-pitfalls class=md-nav__link> <span class=md-ellipsis> Common Mistakes and Pitfalls </span> </a> </li> <li class=md-nav__item> <a href=#further-reading class=md-nav__link> <span class=md-ellipsis> Further Reading </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=chapter-10-ai-fundamentals-for-investigators>Chapter 10: AI Fundamentals for Investigators<a class=headerlink href=#chapter-10-ai-fundamentals-for-investigators title="Permanent link">&para;</a></h1> <h2 id=learning-objectives>Learning Objectives<a class=headerlink href=#learning-objectives title="Permanent link">&para;</a></h2> <p>By the end of this chapter, you will be able to: - Understand the core AI and machine learning concepts relevant to OSINT applications - Evaluate AI tools for investigative use on the basis of appropriate criteria - Use large language models (LLMs) and multimodal models as investigative aids - Recognize the limitations, failure modes, and biases of AI systems - Apply AI tools responsibly with appropriate human oversight - Understand the difference between AI as a tool and AI as an autonomous agent</p> <hr> <h2 id=101-why-investigators-must-understand-ai>10.1 Why Investigators Must Understand AI<a class=headerlink href=#101-why-investigators-must-understand-ai title="Permanent link">&para;</a></h2> <p>AI has moved from an experimental curiosity to a production tool reshaping every phase of the intelligence cycle. Investigators who do not understand AI fundamentals will:</p> <ul> <li>Misuse AI tools by trusting outputs that require verification</li> <li>Miss opportunities that AI-enabled workflows provide</li> <li>Be unable to evaluate AI-generated content as part of their investigations</li> <li>Fail to build workflows that leverage AI effectively</li> <li>Be at a competitive disadvantage to colleagues and adversaries who do use AI</li> </ul> <p>This chapter provides the conceptual foundation. The following chapters in Part III apply that foundation to specific OSINT capabilities. None of this requires a machine learning research background. It requires a practitioner's understanding of what these systems do, how they work at a conceptual level, and what their failure modes are.</p> <hr> <h2 id=102-machine-learning-fundamentals>10.2 Machine Learning Fundamentals<a class=headerlink href=#102-machine-learning-fundamentals title="Permanent link">&para;</a></h2> <h3 id=what-machine-learning-is>What Machine Learning Is<a class=headerlink href=#what-machine-learning-is title="Permanent link">&para;</a></h3> <p>Traditional software executes explicit rules written by programmers. Machine learning systems learn patterns from data and generalize those patterns to new inputs.</p> <p><strong>Supervised learning</strong>: A model is trained on labeled examples (input → correct output). The model learns to predict labels for new inputs. Example: a spam filter trained on millions of labeled spam/not-spam emails learns to classify new emails.</p> <p><strong>Unsupervised learning</strong>: A model finds structure in unlabeled data — clusters, patterns, anomalies — without explicit labels. Example: clustering news articles by topic without pre-defined topic labels.</p> <p><strong>Self-supervised learning</strong>: A model learns from the data itself by predicting parts of the input from other parts. This is how large language models are trained: they learn to predict the next word given previous words.</p> <p><strong>Reinforcement learning from human feedback (RLHF)</strong>: The training method used for modern conversational AI. Models are trained to maximize rewards given by human evaluators, steering them toward helpful, harmless, and honest behavior.</p> <h3 id=neural-networks-and-deep-learning>Neural Networks and Deep Learning<a class=headerlink href=#neural-networks-and-deep-learning title="Permanent link">&para;</a></h3> <p>Modern AI systems are built on artificial neural networks — mathematical structures loosely inspired by biological neural networks. Key concepts:</p> <p><strong>Layers</strong>: Neural networks process input through sequences of mathematical transformations (layers). Deep learning refers to networks with many layers.</p> <p><strong>Parameters (weights)</strong>: The learned values that define the network's behavior. Large language models like GPT-4 have hundreds of billions of parameters.</p> <p><strong>Training</strong>: The process of adjusting parameters to minimize prediction error on training data.</p> <p><strong>Inference</strong>: Using a trained model to process new inputs.</p> <p><strong>Fine-tuning</strong>: Adapting a pre-trained model to a specific task or domain by training it on task-specific data.</p> <h3 id=transformers-and-the-attention-mechanism>Transformers and the Attention Mechanism<a class=headerlink href=#transformers-and-the-attention-mechanism title="Permanent link">&para;</a></h3> <p>The transformer architecture — the basis of essentially all modern large language models — processes sequential data by computing attention: how much each element should "attend to" every other element when producing an output.</p> <p>For text: when processing the word "bank" in a sentence, the model attends to context words ("river" or "financial") to determine meaning. This attention mechanism enables capturing long-range dependencies in text that earlier architectures could not handle effectively.</p> <hr> <h2 id=103-large-language-models-what-they-are-and-arent>10.3 Large Language Models: What They Are and Aren't<a class=headerlink href=#103-large-language-models-what-they-are-and-arent title="Permanent link">&para;</a></h2> <p>Large Language Models (LLMs) — GPT-4, Claude, Gemini, LLaMA, and their successors — are the most consequential AI development for OSINT practice. Understanding what they actually are prevents both underuse and overuse.</p> <h3 id=what-llms-actually-do>What LLMs Actually Do<a class=headerlink href=#what-llms-actually-do title="Permanent link">&para;</a></h3> <p>An LLM is a statistical model of language. Given input text, it generates continuation text by sampling from a probability distribution over vocabulary tokens, conditioned on the input.</p> <p>This sounds reductive, but the capability that emerges from this simple objective, trained on enormous text corpora, is remarkable:</p> <ul> <li>Answering questions based on knowledge embedded in training data</li> <li>Summarizing, translating, and rewriting text</li> <li>Extracting structured information from unstructured text</li> <li>Generating plausible text in specified styles and formats</li> <li>Reasoning through problems when prompted appropriately</li> <li>Analyzing code, mathematical expressions, and structured data</li> </ul> <h3 id=what-llms-are-not>What LLMs Are Not<a class=headerlink href=#what-llms-are-not title="Permanent link">&para;</a></h3> <p><strong>LLMs are not search engines.</strong> They cannot retrieve specific facts from the internet in real-time (without tool integration). They generate text based on patterns in training data, not by looking things up.</p> <p><strong>LLMs do not "know" facts with certainty.</strong> They model what text about a topic typically looks like. If training data frequently says "X is the capital of France," the model will output "Paris" when asked — but not because it "knows" Paris is the capital in the way a database knows. It generates what sounds like a confident answer.</p> <p><strong>LLMs hallucinate.</strong> This is the most critical limitation for investigative use. LLMs will confidently generate plausible-sounding but factually incorrect text — invented citations, fabricated quotes, non-existent entities. The frequency and detectability of hallucination varies by model and task, but it is never zero.</p> <p><strong>LLMs have knowledge cutoffs.</strong> Training data ends at a specific date. Events after the cutoff are not known to the model without retrieval augmentation.</p> <p><strong>LLMs can be manipulated.</strong> Adversarial prompts can cause models to behave in unintended ways. Prompt injection attacks — embedding instructions in external content fed to the model — can manipulate model behavior.</p> <h3 id=the-hallucination-problem-for-investigators>The Hallucination Problem for Investigators<a class=headerlink href=#the-hallucination-problem-for-investigators title="Permanent link">&para;</a></h3> <p>Hallucination is not a bug being fixed — it is an inherent property of how these models generate text. For investigative use, this means:</p> <p><strong>Never cite LLM-generated information as a primary source.</strong> The LLM's claim that "John Smith was indicted in 2019" is not investigative evidence. It is a starting point for searching primary sources.</p> <p><strong>Never use LLM-generated quotes.</strong> A model asked to provide quotes from a person will generate plausible-sounding text that may not be anything the person ever said.</p> <p><strong>Always verify dates, statistics, citations, and specific factual claims</strong> generated by LLMs against primary sources before incorporating them in investigative products.</p> <p><strong>LLMs are valuable for analysis, synthesis, and reasoning, not for factual retrieval.</strong> The distinction is critical.</p> <hr> <h2 id=104-the-modern-ai-ecosystem-for-osint>10.4 The Modern AI Ecosystem for OSINT<a class=headerlink href=#104-the-modern-ai-ecosystem-for-osint title="Permanent link">&para;</a></h2> <h3 id=foundation-model-providers>Foundation Model Providers<a class=headerlink href=#foundation-model-providers title="Permanent link">&para;</a></h3> <p><strong>Anthropic Claude</strong>: Strong analytical reasoning, long context windows (useful for processing large documents), and careful instruction-following. Claude's model family includes Opus (most capable), Sonnet (balanced), and Haiku (fastest/cheapest).</p> <p><strong>OpenAI GPT-4/o-series</strong>: Broad capability with excellent code generation and tool use. GPT-4 Vision (and o-series) adds multimodal capability.</p> <p><strong>Google Gemini</strong>: Tight integration with Google services and strong multimodal capability. Gemini Ultra is Google's most capable tier.</p> <p><strong>Meta LLaMA</strong>: Open-weight models that can be run locally, important for privacy-sensitive investigations where sending data to cloud APIs is unacceptable.</p> <p><strong>Mistral</strong>: European open-weight models with strong performance-to-cost ratio.</p> <h3 id=specialized-ai-models-relevant-to-osint>Specialized AI Models Relevant to OSINT<a class=headerlink href=#specialized-ai-models-relevant-to-osint title="Permanent link">&para;</a></h3> <p><strong>Computer Vision models</strong>: CLIP (image-text matching), SAM (image segmentation), object detection models (YOLO variants), OCR models (Tesseract, PaddleOCR), face recognition models.</p> <p><strong>Speech and Audio</strong>: Whisper (OpenAI's speech-to-text), speaker diarization models.</p> <p><strong>Multimodal models</strong>: Models that process both text and images (Claude, GPT-4V, Gemini) enable direct image analysis for OSINT.</p> <p><strong>Entity extraction models</strong>: Fine-tuned NLP models for named entity recognition (spaCy, Hugging Face NLP models).</p> <p><strong>Translation models</strong>: NLLB (Meta), M2M-100, and cloud translation APIs enable processing non-English content.</p> <hr> <h2 id=105-using-llms-in-investigative-practice>10.5 Using LLMs in Investigative Practice<a class=headerlink href=#105-using-llms-in-investigative-practice title="Permanent link">&para;</a></h2> <p>The most productive way to use LLMs in OSINT is as an analytical augmentation layer — accelerating tasks that are tedious at human scale while maintaining human judgment for all significant conclusions.</p> <h3 id=appropriate-llm-use-cases>Appropriate LLM Use Cases<a class=headerlink href=#appropriate-llm-use-cases title="Permanent link">&para;</a></h3> <p><strong>Document summarization</strong>: Processing and summarizing lengthy documents (court filings, SEC documents, news archives) faster than a human can read them. Always verify key claims against the original.</p> <p><strong>Entity and relationship extraction</strong>: Identifying named entities and relationships from unstructured text. LLMs can extract structured data from messy text at a scale impossible manually.</p> <p><strong>Pattern identification in large text corpora</strong>: Asking an LLM to identify themes, contradictions, or anomalies across multiple documents.</p> <p><strong>Translation</strong>: Translating foreign-language content for investigators who don't speak the relevant language. Machine translation has become good enough for investigative purposes, though significant documents warrant professional translation.</p> <p><strong>Hypothesis generation</strong>: Given established facts, asking an LLM to generate plausible hypotheses or alternative explanations. Not a substitute for human analysis, but a useful brainstorming aid.</p> <p><strong>Report drafting</strong>: Accelerating the production of investigation reports from analytical notes. All AI-drafted content must be carefully reviewed.</p> <p><strong>Code generation</strong>: For investigators with technical needs, LLMs accelerate writing Python scripts for data processing, API queries, and analysis automation.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>import</span><span class=w> </span><span class=nn>anthropic</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=n>client</span> <span class=o>=</span> <span class=n>anthropic</span><span class=o>.</span><span class=n>Anthropic</span><span class=p>()</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=k>def</span><span class=w> </span><span class=nf>extract_entities_from_text</span><span class=p>(</span><span class=n>text</span><span class=p>,</span> <span class=n>entity_types</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=sd>    Use Claude to extract named entities and relationships from investigative text</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>    <span class=n>entity_types</span> <span class=o>=</span> <span class=n>entity_types</span> <span class=ow>or</span> <span class=p>[</span><span class=s1>&#39;Person&#39;</span><span class=p>,</span> <span class=s1>&#39;Organization&#39;</span><span class=p>,</span> <span class=s1>&#39;Location&#39;</span><span class=p>,</span> <span class=s1>&#39;Date&#39;</span><span class=p>,</span> <span class=s1>&#39;Financial Amount&#39;</span><span class=p>]</span>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a>    <span class=n>prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;&quot;&quot;You are an OSINT analyst extracting structured information from text.</span>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a><span class=s2>Extract all named entities from the following text. For each entity, provide:</span>
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a><span class=s2>- Entity type (</span><span class=si>{</span><span class=s1>&#39;, &#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>entity_types</span><span class=p>)</span><span class=si>}</span><span class=s2>)</span>
</span><span id=__span-0-15><a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a><span class=s2>- Entity name (as it appears in text)</span>
</span><span id=__span-0-16><a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a><span class=s2>- Context (brief quote showing how it appears)</span>
</span><span id=__span-0-17><a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a><span class=s2>- Relationships to other entities mentioned</span>
</span><span id=__span-0-18><a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a>
</span><span id=__span-0-19><a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a><span class=s2>Text to analyze:</span>
</span><span id=__span-0-20><a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a><span class=si>{</span><span class=n>text</span><span class=si>}</span>
</span><span id=__span-0-21><a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a>
</span><span id=__span-0-22><a id=__codelineno-0-22 name=__codelineno-0-22 href=#__codelineno-0-22></a><span class=s2>Output as a structured list. Be precise and conservative — only extract entities clearly mentioned in the text. Do not infer or add information not present.&quot;&quot;&quot;</span>
</span><span id=__span-0-23><a id=__codelineno-0-23 name=__codelineno-0-23 href=#__codelineno-0-23></a>
</span><span id=__span-0-24><a id=__codelineno-0-24 name=__codelineno-0-24 href=#__codelineno-0-24></a>    <span class=n>message</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>messages</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span><span id=__span-0-25><a id=__codelineno-0-25 name=__codelineno-0-25 href=#__codelineno-0-25></a>        <span class=n>model</span><span class=o>=</span><span class=s2>&quot;claude-sonnet-4-6&quot;</span><span class=p>,</span>
</span><span id=__span-0-26><a id=__codelineno-0-26 name=__codelineno-0-26 href=#__codelineno-0-26></a>        <span class=n>max_tokens</span><span class=o>=</span><span class=mi>2048</span><span class=p>,</span>
</span><span id=__span-0-27><a id=__codelineno-0-27 name=__codelineno-0-27 href=#__codelineno-0-27></a>        <span class=n>messages</span><span class=o>=</span><span class=p>[{</span><span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;user&quot;</span><span class=p>,</span> <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=n>prompt</span><span class=p>}]</span>
</span><span id=__span-0-28><a id=__codelineno-0-28 name=__codelineno-0-28 href=#__codelineno-0-28></a>    <span class=p>)</span>
</span><span id=__span-0-29><a id=__codelineno-0-29 name=__codelineno-0-29 href=#__codelineno-0-29></a>
</span><span id=__span-0-30><a id=__codelineno-0-30 name=__codelineno-0-30 href=#__codelineno-0-30></a>    <span class=k>return</span> <span class=n>message</span><span class=o>.</span><span class=n>content</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>text</span>
</span><span id=__span-0-31><a id=__codelineno-0-31 name=__codelineno-0-31 href=#__codelineno-0-31></a>
</span><span id=__span-0-32><a id=__codelineno-0-32 name=__codelineno-0-32 href=#__codelineno-0-32></a><span class=k>def</span><span class=w> </span><span class=nf>summarize_document</span><span class=p>(</span><span class=n>document_text</span><span class=p>,</span> <span class=n>focus_questions</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span><span id=__span-0-33><a id=__codelineno-0-33 name=__codelineno-0-33 href=#__codelineno-0-33></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-34><a id=__codelineno-0-34 name=__codelineno-0-34 href=#__codelineno-0-34></a><span class=sd>    Summarize a document with focus on specific investigative questions</span>
</span><span id=__span-0-35><a id=__codelineno-0-35 name=__codelineno-0-35 href=#__codelineno-0-35></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-36><a id=__codelineno-0-36 name=__codelineno-0-36 href=#__codelineno-0-36></a>    <span class=n>focus</span> <span class=o>=</span> <span class=s2>&quot;&quot;</span>
</span><span id=__span-0-37><a id=__codelineno-0-37 name=__codelineno-0-37 href=#__codelineno-0-37></a>    <span class=k>if</span> <span class=n>focus_questions</span><span class=p>:</span>
</span><span id=__span-0-38><a id=__codelineno-0-38 name=__codelineno-0-38 href=#__codelineno-0-38></a>        <span class=n>focus</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n\n</span><span class=s2>Pay particular attention to:</span><span class=se>\n</span><span class=s2>&quot;</span> <span class=o>+</span> <span class=s2>&quot;</span><span class=se>\n</span><span class=s2>&quot;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;- </span><span class=si>{</span><span class=n>q</span><span class=si>}</span><span class=s2>&quot;</span> <span class=k>for</span> <span class=n>q</span> <span class=ow>in</span> <span class=n>focus_questions</span><span class=p>)</span>
</span><span id=__span-0-39><a id=__codelineno-0-39 name=__codelineno-0-39 href=#__codelineno-0-39></a>
</span><span id=__span-0-40><a id=__codelineno-0-40 name=__codelineno-0-40 href=#__codelineno-0-40></a>    <span class=n>prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;&quot;&quot;Summarize the following document for an investigative analyst.</span>
</span><span id=__span-0-41><a id=__codelineno-0-41 name=__codelineno-0-41 href=#__codelineno-0-41></a>
</span><span id=__span-0-42><a id=__codelineno-0-42 name=__codelineno-0-42 href=#__codelineno-0-42></a><span class=s2>Provide:</span>
</span><span id=__span-0-43><a id=__codelineno-0-43 name=__codelineno-0-43 href=#__codelineno-0-43></a><span class=s2>1. Document type and source (if apparent)</span>
</span><span id=__span-0-44><a id=__codelineno-0-44 name=__codelineno-0-44 href=#__codelineno-0-44></a><span class=s2>2. Key findings and facts</span>
</span><span id=__span-0-45><a id=__codelineno-0-45 name=__codelineno-0-45 href=#__codelineno-0-45></a><span class=s2>3. Significant persons, organizations, and locations mentioned</span>
</span><span id=__span-0-46><a id=__codelineno-0-46 name=__codelineno-0-46 href=#__codelineno-0-46></a><span class=s2>4. Dates and timeline of events</span>
</span><span id=__span-0-47><a id=__codelineno-0-47 name=__codelineno-0-47 href=#__codelineno-0-47></a><span class=s2>5. Any contradictions, unusual statements, or areas requiring verification</span><span class=si>{</span><span class=n>focus</span><span class=si>}</span>
</span><span id=__span-0-48><a id=__codelineno-0-48 name=__codelineno-0-48 href=#__codelineno-0-48></a>
</span><span id=__span-0-49><a id=__codelineno-0-49 name=__codelineno-0-49 href=#__codelineno-0-49></a><span class=s2>Note where important information appears uncertain or requires verification.</span>
</span><span id=__span-0-50><a id=__codelineno-0-50 name=__codelineno-0-50 href=#__codelineno-0-50></a>
</span><span id=__span-0-51><a id=__codelineno-0-51 name=__codelineno-0-51 href=#__codelineno-0-51></a><span class=s2>Document:</span>
</span><span id=__span-0-52><a id=__codelineno-0-52 name=__codelineno-0-52 href=#__codelineno-0-52></a><span class=si>{</span><span class=n>document_text</span><span class=p>[:</span><span class=mi>8000</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;&quot;&quot;</span>  <span class=c1># Claude&#39;s context window handles much more, but truncating for demo</span>
</span><span id=__span-0-53><a id=__codelineno-0-53 name=__codelineno-0-53 href=#__codelineno-0-53></a>
</span><span id=__span-0-54><a id=__codelineno-0-54 name=__codelineno-0-54 href=#__codelineno-0-54></a>    <span class=n>message</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>messages</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span><span id=__span-0-55><a id=__codelineno-0-55 name=__codelineno-0-55 href=#__codelineno-0-55></a>        <span class=n>model</span><span class=o>=</span><span class=s2>&quot;claude-sonnet-4-6&quot;</span><span class=p>,</span>
</span><span id=__span-0-56><a id=__codelineno-0-56 name=__codelineno-0-56 href=#__codelineno-0-56></a>        <span class=n>max_tokens</span><span class=o>=</span><span class=mi>2048</span><span class=p>,</span>
</span><span id=__span-0-57><a id=__codelineno-0-57 name=__codelineno-0-57 href=#__codelineno-0-57></a>        <span class=n>messages</span><span class=o>=</span><span class=p>[{</span><span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;user&quot;</span><span class=p>,</span> <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=n>prompt</span><span class=p>}]</span>
</span><span id=__span-0-58><a id=__codelineno-0-58 name=__codelineno-0-58 href=#__codelineno-0-58></a>    <span class=p>)</span>
</span><span id=__span-0-59><a id=__codelineno-0-59 name=__codelineno-0-59 href=#__codelineno-0-59></a>
</span><span id=__span-0-60><a id=__codelineno-0-60 name=__codelineno-0-60 href=#__codelineno-0-60></a>    <span class=k>return</span> <span class=n>message</span><span class=o>.</span><span class=n>content</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>text</span>
</span><span id=__span-0-61><a id=__codelineno-0-61 name=__codelineno-0-61 href=#__codelineno-0-61></a>
</span><span id=__span-0-62><a id=__codelineno-0-62 name=__codelineno-0-62 href=#__codelineno-0-62></a><span class=k>def</span><span class=w> </span><span class=nf>generate_alternative_hypotheses</span><span class=p>(</span><span class=n>confirmed_facts</span><span class=p>,</span> <span class=n>primary_hypothesis</span><span class=p>):</span>
</span><span id=__span-0-63><a id=__codelineno-0-63 name=__codelineno-0-63 href=#__codelineno-0-63></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-0-64><a id=__codelineno-0-64 name=__codelineno-0-64 href=#__codelineno-0-64></a><span class=sd>    Use AI to generate competing hypotheses for ACH analysis</span>
</span><span id=__span-0-65><a id=__codelineno-0-65 name=__codelineno-0-65 href=#__codelineno-0-65></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-0-66><a id=__codelineno-0-66 name=__codelineno-0-66 href=#__codelineno-0-66></a>    <span class=n>facts_text</span> <span class=o>=</span> <span class=s2>&quot;</span><span class=se>\n</span><span class=s2>&quot;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;- </span><span class=si>{</span><span class=n>f</span><span class=si>}</span><span class=s2>&quot;</span> <span class=k>for</span> <span class=n>f</span> <span class=ow>in</span> <span class=n>confirmed_facts</span><span class=p>)</span>
</span><span id=__span-0-67><a id=__codelineno-0-67 name=__codelineno-0-67 href=#__codelineno-0-67></a>
</span><span id=__span-0-68><a id=__codelineno-0-68 name=__codelineno-0-68 href=#__codelineno-0-68></a>    <span class=n>prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;&quot;&quot;You are an intelligence analyst conducting Analysis of Competing Hypotheses (ACH).</span>
</span><span id=__span-0-69><a id=__codelineno-0-69 name=__codelineno-0-69 href=#__codelineno-0-69></a>
</span><span id=__span-0-70><a id=__codelineno-0-70 name=__codelineno-0-70 href=#__codelineno-0-70></a><span class=s2>Confirmed facts:</span>
</span><span id=__span-0-71><a id=__codelineno-0-71 name=__codelineno-0-71 href=#__codelineno-0-71></a><span class=si>{</span><span class=n>facts_text</span><span class=si>}</span>
</span><span id=__span-0-72><a id=__codelineno-0-72 name=__codelineno-0-72 href=#__codelineno-0-72></a>
</span><span id=__span-0-73><a id=__codelineno-0-73 name=__codelineno-0-73 href=#__codelineno-0-73></a><span class=s2>Primary hypothesis:</span>
</span><span id=__span-0-74><a id=__codelineno-0-74 name=__codelineno-0-74 href=#__codelineno-0-74></a><span class=si>{</span><span class=n>primary_hypothesis</span><span class=si>}</span>
</span><span id=__span-0-75><a id=__codelineno-0-75 name=__codelineno-0-75 href=#__codelineno-0-75></a>
</span><span id=__span-0-76><a id=__codelineno-0-76 name=__codelineno-0-76 href=#__codelineno-0-76></a><span class=s2>Generate 3-5 alternative hypotheses that:</span>
</span><span id=__span-0-77><a id=__codelineno-0-77 name=__codelineno-0-77 href=#__codelineno-0-77></a><span class=s2>1. Are consistent with the available facts</span>
</span><span id=__span-0-78><a id=__codelineno-0-78 name=__codelineno-0-78 href=#__codelineno-0-78></a><span class=s2>2. Represent genuinely different explanations</span>
</span><span id=__span-0-79><a id=__codelineno-0-79 name=__codelineno-0-79 href=#__codelineno-0-79></a><span class=s2>3. Include at least one &quot;null hypothesis&quot; or innocent explanation</span>
</span><span id=__span-0-80><a id=__codelineno-0-80 name=__codelineno-0-80 href=#__codelineno-0-80></a><span class=s2>4. Include a hypothesis that considers deliberate deception</span>
</span><span id=__span-0-81><a id=__codelineno-0-81 name=__codelineno-0-81 href=#__codelineno-0-81></a>
</span><span id=__span-0-82><a id=__codelineno-0-82 name=__codelineno-0-82 href=#__codelineno-0-82></a><span class=s2>For each alternative hypothesis, note:</span>
</span><span id=__span-0-83><a id=__codelineno-0-83 name=__codelineno-0-83 href=#__codelineno-0-83></a><span class=s2>- Which facts support it</span>
</span><span id=__span-0-84><a id=__codelineno-0-84 name=__codelineno-0-84 href=#__codelineno-0-84></a><span class=s2>- Which facts are inconsistent with it</span>
</span><span id=__span-0-85><a id=__codelineno-0-85 name=__codelineno-0-85 href=#__codelineno-0-85></a><span class=s2>- What additional evidence would confirm or refute it</span>
</span><span id=__span-0-86><a id=__codelineno-0-86 name=__codelineno-0-86 href=#__codelineno-0-86></a>
</span><span id=__span-0-87><a id=__codelineno-0-87 name=__codelineno-0-87 href=#__codelineno-0-87></a><span class=s2>Be analytical and avoid reaching conclusions beyond what the facts support.&quot;&quot;&quot;</span>
</span><span id=__span-0-88><a id=__codelineno-0-88 name=__codelineno-0-88 href=#__codelineno-0-88></a>
</span><span id=__span-0-89><a id=__codelineno-0-89 name=__codelineno-0-89 href=#__codelineno-0-89></a>    <span class=n>message</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>messages</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span><span id=__span-0-90><a id=__codelineno-0-90 name=__codelineno-0-90 href=#__codelineno-0-90></a>        <span class=n>model</span><span class=o>=</span><span class=s2>&quot;claude-sonnet-4-6&quot;</span><span class=p>,</span>
</span><span id=__span-0-91><a id=__codelineno-0-91 name=__codelineno-0-91 href=#__codelineno-0-91></a>        <span class=n>max_tokens</span><span class=o>=</span><span class=mi>2048</span><span class=p>,</span>
</span><span id=__span-0-92><a id=__codelineno-0-92 name=__codelineno-0-92 href=#__codelineno-0-92></a>        <span class=n>messages</span><span class=o>=</span><span class=p>[{</span><span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;user&quot;</span><span class=p>,</span> <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=n>prompt</span><span class=p>}]</span>
</span><span id=__span-0-93><a id=__codelineno-0-93 name=__codelineno-0-93 href=#__codelineno-0-93></a>    <span class=p>)</span>
</span><span id=__span-0-94><a id=__codelineno-0-94 name=__codelineno-0-94 href=#__codelineno-0-94></a>
</span><span id=__span-0-95><a id=__codelineno-0-95 name=__codelineno-0-95 href=#__codelineno-0-95></a>    <span class=k>return</span> <span class=n>message</span><span class=o>.</span><span class=n>content</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>text</span>
</span></code></pre></div> <h3 id=inappropriate-llm-use-cases>Inappropriate LLM Use Cases<a class=headerlink href=#inappropriate-llm-use-cases title="Permanent link">&para;</a></h3> <p><strong>Primary source research</strong>: Using LLMs to answer "where does John Smith live?" rather than searching public records. The LLM may fabricate a plausible-sounding but false answer.</p> <p><strong>Factual citation</strong>: Using an LLM's claim as evidence of a fact without verification.</p> <p><strong>Identifying individuals in images</strong>: LLMs with vision capability should not be used to identify specific individuals from photographs without extreme verification caution.</p> <p><strong>Generating quotes or statements attributed to real people</strong>: This creates serious misrepresentation risks.</p> <hr> <h2 id=106-multimodal-ai-for-osint>10.6 Multimodal AI for OSINT<a class=headerlink href=#106-multimodal-ai-for-osint title="Permanent link">&para;</a></h2> <p>Multimodal models that process both text and images have opened new OSINT capabilities:</p> <p><strong>Image description and analysis</strong>: Asking a vision model to describe image content, identify objects, read visible text, and characterize the scene.</p> <p><strong>Document processing</strong>: Processing scanned documents, photographs of text, or handwritten content.</p> <p><strong>Visual geolocation assistance</strong>: As discussed in Chapter 8, vision models can help identify geographic indicators in images.</p> <p><strong>Video frame analysis</strong>: Extracting and analyzing individual frames from video content.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=kn>import</span><span class=w> </span><span class=nn>anthropic</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=kn>import</span><span class=w> </span><span class=nn>base64</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a><span class=kn>import</span><span class=w> </span><span class=nn>httpx</span>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a><span class=k>def</span><span class=w> </span><span class=nf>analyze_image_for_osint</span><span class=p>(</span><span class=n>image_source</span><span class=p>,</span> <span class=n>investigation_context</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a><span class=sd>    Analyze an image using Claude&#39;s vision capability for OSINT purposes</span>
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a><span class=sd>    image_source: URL or file path</span>
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a><span class=sd>    &quot;&quot;&quot;</span>
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a>    <span class=n>client</span> <span class=o>=</span> <span class=n>anthropic</span><span class=o>.</span><span class=n>Anthropic</span><span class=p>()</span>
</span><span id=__span-1-11><a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a>
</span><span id=__span-1-12><a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a>    <span class=c1># Load image</span>
</span><span id=__span-1-13><a id=__codelineno-1-13 name=__codelineno-1-13 href=#__codelineno-1-13></a>    <span class=k>if</span> <span class=n>image_source</span><span class=o>.</span><span class=n>startswith</span><span class=p>(</span><span class=s1>&#39;http&#39;</span><span class=p>):</span>
</span><span id=__span-1-14><a id=__codelineno-1-14 name=__codelineno-1-14 href=#__codelineno-1-14></a>        <span class=n>image_data</span> <span class=o>=</span> <span class=n>base64</span><span class=o>.</span><span class=n>standard_b64encode</span><span class=p>(</span>
</span><span id=__span-1-15><a id=__codelineno-1-15 name=__codelineno-1-15 href=#__codelineno-1-15></a>            <span class=n>httpx</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>image_source</span><span class=p>)</span><span class=o>.</span><span class=n>content</span>
</span><span id=__span-1-16><a id=__codelineno-1-16 name=__codelineno-1-16 href=#__codelineno-1-16></a>        <span class=p>)</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=s2>&quot;utf-8&quot;</span><span class=p>)</span>
</span><span id=__span-1-17><a id=__codelineno-1-17 name=__codelineno-1-17 href=#__codelineno-1-17></a>        <span class=n>media_type</span> <span class=o>=</span> <span class=s2>&quot;image/jpeg&quot;</span>  <span class=c1># Adjust based on actual type</span>
</span><span id=__span-1-18><a id=__codelineno-1-18 name=__codelineno-1-18 href=#__codelineno-1-18></a>    <span class=k>else</span><span class=p>:</span>
</span><span id=__span-1-19><a id=__codelineno-1-19 name=__codelineno-1-19 href=#__codelineno-1-19></a>        <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>image_source</span><span class=p>,</span> <span class=s1>&#39;rb&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span><span id=__span-1-20><a id=__codelineno-1-20 name=__codelineno-1-20 href=#__codelineno-1-20></a>            <span class=n>image_data</span> <span class=o>=</span> <span class=n>base64</span><span class=o>.</span><span class=n>b64encode</span><span class=p>(</span><span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>())</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=s1>&#39;utf-8&#39;</span><span class=p>)</span>
</span><span id=__span-1-21><a id=__codelineno-1-21 name=__codelineno-1-21 href=#__codelineno-1-21></a>        <span class=c1># Detect media type from extension</span>
</span><span id=__span-1-22><a id=__codelineno-1-22 name=__codelineno-1-22 href=#__codelineno-1-22></a>        <span class=n>ext</span> <span class=o>=</span> <span class=n>image_source</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;.&#39;</span><span class=p>)[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span><span id=__span-1-23><a id=__codelineno-1-23 name=__codelineno-1-23 href=#__codelineno-1-23></a>        <span class=n>media_type</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;jpg&#39;</span><span class=p>:</span> <span class=s1>&#39;image/jpeg&#39;</span><span class=p>,</span> <span class=s1>&#39;jpeg&#39;</span><span class=p>:</span> <span class=s1>&#39;image/jpeg&#39;</span><span class=p>,</span>
</span><span id=__span-1-24><a id=__codelineno-1-24 name=__codelineno-1-24 href=#__codelineno-1-24></a>                     <span class=s1>&#39;png&#39;</span><span class=p>:</span> <span class=s1>&#39;image/png&#39;</span><span class=p>,</span> <span class=s1>&#39;gif&#39;</span><span class=p>:</span> <span class=s1>&#39;image/gif&#39;</span><span class=p>,</span>
</span><span id=__span-1-25><a id=__codelineno-1-25 name=__codelineno-1-25 href=#__codelineno-1-25></a>                     <span class=s1>&#39;webp&#39;</span><span class=p>:</span> <span class=s1>&#39;image/webp&#39;</span><span class=p>}</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>ext</span><span class=p>,</span> <span class=s1>&#39;image/jpeg&#39;</span><span class=p>)</span>
</span><span id=__span-1-26><a id=__codelineno-1-26 name=__codelineno-1-26 href=#__codelineno-1-26></a>
</span><span id=__span-1-27><a id=__codelineno-1-27 name=__codelineno-1-27 href=#__codelineno-1-27></a>    <span class=n>context_instruction</span> <span class=o>=</span> <span class=s2>&quot;&quot;</span>
</span><span id=__span-1-28><a id=__codelineno-1-28 name=__codelineno-1-28 href=#__codelineno-1-28></a>    <span class=k>if</span> <span class=n>investigation_context</span><span class=p>:</span>
</span><span id=__span-1-29><a id=__codelineno-1-29 name=__codelineno-1-29 href=#__codelineno-1-29></a>        <span class=n>context_instruction</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n\n</span><span class=s2>Investigation context: </span><span class=si>{</span><span class=n>investigation_context</span><span class=si>}</span><span class=s2>&quot;</span>
</span><span id=__span-1-30><a id=__codelineno-1-30 name=__codelineno-1-30 href=#__codelineno-1-30></a>
</span><span id=__span-1-31><a id=__codelineno-1-31 name=__codelineno-1-31 href=#__codelineno-1-31></a>    <span class=n>message</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>messages</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span><span id=__span-1-32><a id=__codelineno-1-32 name=__codelineno-1-32 href=#__codelineno-1-32></a>        <span class=n>model</span><span class=o>=</span><span class=s2>&quot;claude-sonnet-4-6&quot;</span><span class=p>,</span>
</span><span id=__span-1-33><a id=__codelineno-1-33 name=__codelineno-1-33 href=#__codelineno-1-33></a>        <span class=n>max_tokens</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>
</span><span id=__span-1-34><a id=__codelineno-1-34 name=__codelineno-1-34 href=#__codelineno-1-34></a>        <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span><span id=__span-1-35><a id=__codelineno-1-35 name=__codelineno-1-35 href=#__codelineno-1-35></a>            <span class=p>{</span>
</span><span id=__span-1-36><a id=__codelineno-1-36 name=__codelineno-1-36 href=#__codelineno-1-36></a>                <span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;user&quot;</span><span class=p>,</span>
</span><span id=__span-1-37><a id=__codelineno-1-37 name=__codelineno-1-37 href=#__codelineno-1-37></a>                <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=p>[</span>
</span><span id=__span-1-38><a id=__codelineno-1-38 name=__codelineno-1-38 href=#__codelineno-1-38></a>                    <span class=p>{</span>
</span><span id=__span-1-39><a id=__codelineno-1-39 name=__codelineno-1-39 href=#__codelineno-1-39></a>                        <span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;image&quot;</span><span class=p>,</span>
</span><span id=__span-1-40><a id=__codelineno-1-40 name=__codelineno-1-40 href=#__codelineno-1-40></a>                        <span class=s2>&quot;source&quot;</span><span class=p>:</span> <span class=p>{</span>
</span><span id=__span-1-41><a id=__codelineno-1-41 name=__codelineno-1-41 href=#__codelineno-1-41></a>                            <span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;base64&quot;</span><span class=p>,</span>
</span><span id=__span-1-42><a id=__codelineno-1-42 name=__codelineno-1-42 href=#__codelineno-1-42></a>                            <span class=s2>&quot;media_type&quot;</span><span class=p>:</span> <span class=n>media_type</span><span class=p>,</span>
</span><span id=__span-1-43><a id=__codelineno-1-43 name=__codelineno-1-43 href=#__codelineno-1-43></a>                            <span class=s2>&quot;data&quot;</span><span class=p>:</span> <span class=n>image_data</span><span class=p>,</span>
</span><span id=__span-1-44><a id=__codelineno-1-44 name=__codelineno-1-44 href=#__codelineno-1-44></a>                        <span class=p>},</span>
</span><span id=__span-1-45><a id=__codelineno-1-45 name=__codelineno-1-45 href=#__codelineno-1-45></a>                    <span class=p>},</span>
</span><span id=__span-1-46><a id=__codelineno-1-46 name=__codelineno-1-46 href=#__codelineno-1-46></a>                    <span class=p>{</span>
</span><span id=__span-1-47><a id=__codelineno-1-47 name=__codelineno-1-47 href=#__codelineno-1-47></a>                        <span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;text&quot;</span><span class=p>,</span>
</span><span id=__span-1-48><a id=__codelineno-1-48 name=__codelineno-1-48 href=#__codelineno-1-48></a>                        <span class=s2>&quot;text&quot;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&quot;&quot;&quot;Analyze this image from an open-source intelligence perspective.</span>
</span><span id=__span-1-49><a id=__codelineno-1-49 name=__codelineno-1-49 href=#__codelineno-1-49></a>
</span><span id=__span-1-50><a id=__codelineno-1-50 name=__codelineno-1-50 href=#__codelineno-1-50></a><span class=s2>Identify and describe:</span>
</span><span id=__span-1-51><a id=__codelineno-1-51 name=__codelineno-1-51 href=#__codelineno-1-51></a><span class=s2>1. Visible text (signs, labels, documents, licenses plates — read exactly as shown)</span>
</span><span id=__span-1-52><a id=__codelineno-1-52 name=__codelineno-1-52 href=#__codelineno-1-52></a><span class=s2>2. People present (physical descriptions only, do not attempt to identify)</span>
</span><span id=__span-1-53><a id=__codelineno-1-53 name=__codelineno-1-53 href=#__codelineno-1-53></a><span class=s2>3. Objects and items of potential investigative interest</span>
</span><span id=__span-1-54><a id=__codelineno-1-54 name=__codelineno-1-54 href=#__codelineno-1-54></a><span class=s2>4. Location indicators (geography, climate, cultural markers, infrastructure)</span>
</span><span id=__span-1-55><a id=__codelineno-1-55 name=__codelineno-1-55 href=#__codelineno-1-55></a><span class=s2>5. Time indicators (weather, lighting, visible dates, seasonal markers)</span>
</span><span id=__span-1-56><a id=__codelineno-1-56 name=__codelineno-1-56 href=#__codelineno-1-56></a><span class=s2>6. Vehicles (type, make if identifiable, license plate format/region)</span>
</span><span id=__span-1-57><a id=__codelineno-1-57 name=__codelineno-1-57 href=#__codelineno-1-57></a><span class=s2>7. Organizational/brand indicators (logos, uniforms, markings)</span>
</span><span id=__span-1-58><a id=__codelineno-1-58 name=__codelineno-1-58 href=#__codelineno-1-58></a>
</span><span id=__span-1-59><a id=__codelineno-1-59 name=__codelineno-1-59 href=#__codelineno-1-59></a><span class=s2>Note the quality and reliability of each observation. Do not speculate beyond what is clearly visible.</span><span class=si>{</span><span class=n>context_instruction</span><span class=si>}</span><span class=s2>&quot;&quot;&quot;</span>
</span><span id=__span-1-60><a id=__codelineno-1-60 name=__codelineno-1-60 href=#__codelineno-1-60></a>                    <span class=p>}</span>
</span><span id=__span-1-61><a id=__codelineno-1-61 name=__codelineno-1-61 href=#__codelineno-1-61></a>                <span class=p>],</span>
</span><span id=__span-1-62><a id=__codelineno-1-62 name=__codelineno-1-62 href=#__codelineno-1-62></a>            <span class=p>}</span>
</span><span id=__span-1-63><a id=__codelineno-1-63 name=__codelineno-1-63 href=#__codelineno-1-63></a>        <span class=p>],</span>
</span><span id=__span-1-64><a id=__codelineno-1-64 name=__codelineno-1-64 href=#__codelineno-1-64></a>    <span class=p>)</span>
</span><span id=__span-1-65><a id=__codelineno-1-65 name=__codelineno-1-65 href=#__codelineno-1-65></a>
</span><span id=__span-1-66><a id=__codelineno-1-66 name=__codelineno-1-66 href=#__codelineno-1-66></a>    <span class=k>return</span> <span class=n>message</span><span class=o>.</span><span class=n>content</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>text</span>
</span></code></pre></div> <hr> <h2 id=107-ai-bias-and-its-investigative-implications>10.7 AI Bias and Its Investigative Implications<a class=headerlink href=#107-ai-bias-and-its-investigative-implications title="Permanent link">&para;</a></h2> <p>AI systems encode the biases present in their training data. For investigators, this creates serious risks:</p> <p><strong>Demographic bias</strong>: Face recognition systems have documented higher error rates for women and people of color. Using biased AI for identity verification in investigations creates systematic unfairness.</p> <p><strong>Geographic bias</strong>: AI models trained primarily on English-language Western content have reduced accuracy for non-English content, non-Western cultural contexts, and less-represented geographic regions.</p> <p><strong>Temporal bias</strong>: AI models trained on historical data reflect historical patterns and biases. These may not apply to current situations.</p> <p><strong>Selection bias</strong>: Training data is never a random sample of all possible inputs. The populations and scenarios overrepresented in training data receive better performance.</p> <p><strong>Amplification bias</strong>: AI models can amplify biases present in their training data to produce outputs more extreme than the training patterns.</p> <p><strong>Practical mitigations</strong>: - Use AI tools as hypothesis generators, not conclusion producers - Verify AI findings through human review and primary source corroboration - Be explicitly skeptical of AI outputs involving populations where you know the model has limited training data - Test AI tools on examples where the correct answer is known before using them for unknown cases - Document AI tool use and its limitations in investigative methodology notes</p> <hr> <h2 id=108-responsible-ai-use-in-investigations>10.8 Responsible AI Use in Investigations<a class=headerlink href=#108-responsible-ai-use-in-investigations title="Permanent link">&para;</a></h2> <h3 id=the-human-oversight-requirement>The Human Oversight Requirement<a class=headerlink href=#the-human-oversight-requirement title="Permanent link">&para;</a></h3> <p>For every investigative conclusion that will be acted upon — that will be included in a report, shared with a client, used as the basis for legal action, or published — a human must have:</p> <ol> <li>Reviewed the AI output</li> <li>Verified supporting evidence against primary sources</li> <li>Applied professional judgment about confidence and accuracy</li> <li>Taken personal responsibility for the finding</li> </ol> <p>"The AI said so" is not an acceptable basis for a professional investigative conclusion.</p> <h3 id=prompt-design-for-investigative-use>Prompt Design for Investigative Use<a class=headerlink href=#prompt-design-for-investigative-use title="Permanent link">&para;</a></h3> <p>Effective use of LLMs in investigations requires careful prompt design:</p> <p><strong>Be explicit about the task</strong>: Vague prompts produce vague outputs. "Tell me about this company" is worse than "Extract all disclosed related-party transactions from this proxy statement."</p> <p><strong>Specify output format</strong>: "Provide a bullet-pointed list of..." or "Respond in JSON format with fields..." produces more usable outputs than unconstrained generation.</p> <p><strong>Instruct for uncertainty disclosure</strong>: "Note where you are uncertain or where the text does not clearly support your conclusion."</p> <p><strong>Provide context</strong>: "You are analyzing an SEC proxy statement. Identify..." gives the model relevant context for accurate analysis.</p> <p><strong>Calibrate confidence</strong>: "Rate your confidence in each finding as high, medium, or low."</p> <h3 id=data-privacy-in-ai-tool-use>Data Privacy in AI Tool Use<a class=headerlink href=#data-privacy-in-ai-tool-use title="Permanent link">&para;</a></h3> <p>Sending sensitive investigation data to cloud AI APIs creates privacy and confidentiality considerations:</p> <ul> <li>Client data, subject data, and investigative findings fed to cloud APIs are transmitted to and processed by the API provider</li> <li>API providers' data handling policies vary in how they treat input data</li> <li>Sensitive investigations may require use of locally-deployed models (LLaMA, Mistral) rather than cloud APIs</li> <li>API usage agreements should be reviewed for data retention and training provisions</li> </ul> <hr> <h2 id=summary>Summary<a class=headerlink href=#summary title="Permanent link">&para;</a></h2> <p>AI has become an unavoidable component of modern OSINT practice. Understanding AI fundamentals — what machine learning is, how large language models work, what their limitations are — enables investigators to use these tools effectively and avoid their failure modes.</p> <p>LLMs are powerful analytical aids for document processing, entity extraction, hypothesis generation, and translation. They are not reliable factual sources and hallucinate with meaningful frequency. Human oversight of AI outputs is mandatory for all consequential investigative work.</p> <p>Multimodal models extend AI capability to image and document analysis. AI bias is a real consideration that requires explicit attention, particularly for investigations involving populations or geographies underrepresented in training data.</p> <p>The responsible use of AI in investigations treats AI as an accelerant for human analysis, not a replacement for it.</p> <hr> <h2 id=common-mistakes-and-pitfalls>Common Mistakes and Pitfalls<a class=headerlink href=#common-mistakes-and-pitfalls title="Permanent link">&para;</a></h2> <ul> <li><strong>Citing LLM outputs as facts</strong>: AI-generated factual claims require verification against primary sources</li> <li><strong>Trusting AI confidence signals</strong>: Models that output "I'm confident that..." are not necessarily more accurate</li> <li><strong>Ignoring hallucination risk for dates, statistics, and citations</strong>: These specific output types have elevated hallucination rates</li> <li><strong>Using cloud AI for sensitive data without reviewing data policies</strong>: Investigative data requires confidentiality; cloud API data handling varies</li> <li><strong>Treating AI limitation disclosures as disclaimers to skip</strong>: Model limitations are operational constraints, not legal boilerplate</li> <li><strong>Not specifying output format</strong>: Unstructured AI outputs are harder to use and verify than structured ones</li> </ul> <hr> <h2 id=further-reading>Further Reading<a class=headerlink href=#further-reading title="Permanent link">&para;</a></h2> <ul> <li>Anthropic model documentation — model capabilities and limitations</li> <li>OpenAI GPT-4 technical report — capability and evaluation documentation</li> <li>Emily Bender et al., "On the Dangers of Stochastic Parrots" — the foundational academic critique of LLMs</li> <li>Timnit Gebru and colleagues' work on AI bias</li> <li>AI and democracy/misinformation research from the Partnership on AI and AI Now Institute</li> </ul> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../chapter-09/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Ch 9: Advanced Search and Historical Data"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Ch 9: Advanced Search and Historical Data </div> </div> </a> <a href=../chapter-11/ class="md-footer__link md-footer__link--next" aria-label="Next: Ch 11: Processing Unstructured Data at Scale"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Ch 11: Processing Unstructured Data at Scale </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2025 CloudStreet </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/cloudstreet-dev/The-Open-Source-Intelligence-Bible target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.top", "navigation.footer", "search.highlight", "search.suggest", "content.code.copy", "content.code.annotate", "toc.follow"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.79ae519e.min.js></script> </body> </html>